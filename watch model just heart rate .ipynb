{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import keras\n",
    "from functools import reduce\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=pd.read_csv('/Users/mahnooshsadeghi/Desktop/PTSD/PTSD Data/HR Features/HR Features_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2=pd.read_csv('/Users/mahnooshsadeghi/Desktop/PTSD/PTSD Data/Linear Accerelation Features/Linear Accerelation Features_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3=pd.read_csv('/Users/mahnooshsadeghi/Desktop/PTSD/PTSD Data/Angular Accerelation Features/Angular Accerelation Features_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(frame1,frame2,on=[\"windowno\",\"participant\", 'ptsd_moment'])\n",
    "frame= pd.merge(result,frame3,on=[\"windowno\",\"participant\", 'ptsd_moment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=frame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windowno          0\n",
       "hrmean            0\n",
       "hrmin             0\n",
       "hrmax             0\n",
       "hrsd              0\n",
       "ptsd_moment       0\n",
       "participant       0\n",
       "hrrange           0\n",
       "linaccmean        0\n",
       "linaccmin         0\n",
       "linaccmax         0\n",
       "linaccsd          0\n",
       "linear_accel_x    0\n",
       "linear_accel_y    0\n",
       "linear_accel_z    0\n",
       "linaccrange       0\n",
       "acc_x             0\n",
       "acc_y             0\n",
       "acc_z             0\n",
       "acc_xmin          0\n",
       "acc_ymin          0\n",
       "acc_zmin          0\n",
       "acc_xmax          0\n",
       "acc_ymax          0\n",
       "acc_zmax          0\n",
       "acc_xsd           0\n",
       "acc_ysd           0\n",
       "acc_zsd           0\n",
       "acc_xrange        0\n",
       "acc_yrange        0\n",
       "acc_zrange        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X= frame[['linaccmean','linaccmin','linaccmax','linaccsd', 'linear_accel_x',\n",
    " #         'linear_accel_y','linear_accel_z','linaccrange',\n",
    "  #        'hrmax', 'hrmean','hrmin','hrrange','hrsd']]\n",
    "\n",
    "\n",
    "\n",
    "X= frame[['hrmax', 'hrmean','hrmin','hrrange','hrsd']]\n",
    "#X= frameunder[['acc_x','acc_y','acc_z','linear_accel_x','linear_accel_y','linear_accel_z','linacc','hrmax', 'hrmean','hrmin','hrrange','hrsd']]\n",
    "y= frame[['ptsd_moment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame0 = df[df['ptsd_moment'] ==0]\n",
    "frame1 = df[df['ptsd_moment'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = df.ptsd_moment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8958"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=0.75*count_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_class_1_over = frame1.sample(int(ratio), replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameover = pd.concat([frame0, frame_class_1_over], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save training dataset\n",
    "\n",
    "#frameover.to_csv (r'/Users/mahnooshsadeghi/Desktop/PTSD/PTSD Data/Training and Testing Data Sets/Training Data Set (without acc).csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingdataset = pd.concat([X_test,y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hrmax          3993\n",
       "hrmean         3993\n",
       "hrmin          3993\n",
       "hrrange        3993\n",
       "hrsd           3993\n",
       "ptsd_moment    3993\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingdataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save testing dataset\n",
    "\n",
    "#testingdataset.to_csv (r'/Users/mahnooshsadeghi/Desktop/PTSD/PTSD Data/Training and Testing Data Sets/Testing Data Set (without acc).csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_trainups= frameover[['acc_x','acc_y','acc_z','acc_xmin','acc_ymin',\n",
    " #         'acc_zmin','acc_xmax','acc_ymax','acc_zmax','acc_xsd',\n",
    "  #        'acc_ysd','acc_zsd','acc_xrange','acc_yrange','acc_zrange', 'linaccmean','linaccmin','linaccmax','linaccsd', 'linear_accel_x',\n",
    "   #       'linear_accel_y','linear_accel_z','linaccrange',\n",
    "    #      'hrmax', 'hrmean','hrmin','hrrange','hrsd']]\n",
    "\n",
    "    \n",
    "X_trainups= frameover[[ 'hrmax', 'hrmean','hrmin','hrrange','hrsd']]    \n",
    "#X= frameunder[['acc_x','acc_y','acc_z','linear_accel_x','linear_accel_y','linear_accel_z','linacc','hrmax', 'hrmean','hrmin','hrrange','hrsd']]\n",
    "y_trainups= frameover[['ptsd_moment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLVE XGBOOST NAME MISMATCH\n",
    "\n",
    "X_trainupsarray = X_trainups.to_numpy()\n",
    "y_trainupsarray= y_trainups.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainupsarray.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= XGBClassifier ()\n",
    "#clf= RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//miniconda3/envs/PTSD/lib/python3.7/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_trainups,y_trainups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 1.14.0 detected. Last version known to be fully compatible is 1.13.1 .\n",
      "WARNING:root:Keras version 2.3.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "#For the watch and putting model on the watch\n",
    "import coremltools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model = coremltools.converters.xgboost.convert(clf._Booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.save('my_modelhrforwatch.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "predictions=clf.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict_proba(X_test)\n",
    "\n",
    "# take the second column because the classifier outputs scores for\n",
    "# the 0 class as well\n",
    "preds = y_preds[:,1]\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr means false-positive-rate\n",
    "# tpr means true-positive-rate\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "auc_score = metrics.auc(fpr, tpr)\n",
    "\n",
    "# clear current figure\n",
    "plt.clf()\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\n",
    "\n",
    "# it's helpful to add a diagonal to indicate where chance \n",
    "# scores lie (i.e. just flipping a coin)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "#It either does plot show ot plot save if you wanna save the plot make sure you don't execute plt show\n",
    "#plt.show()\n",
    "plt.savefig('Xgboost.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "from xgboost import plot_importance\n",
    "plot_importance(clf)\n",
    "#plt.show()\n",
    "plt.savefig('FeatureImportanceXgboost.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance xgoost and xgboostregressor\n",
    "fi = pd.DataFrame({'feature': list(X_trainups.columns),\n",
    "                   'importance': clf.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), \n",
    "                         index=['NO PTSD','PTSD'], \n",
    "                         columns=['NO PTSD','PTSD'])\n",
    "Confusion\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
